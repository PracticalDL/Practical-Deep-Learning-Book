{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"center\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud APIs for Computer Vision: Up and Running in 15 Minutes\n",
    "\n",
    "This code is part of [Chapter 8- Cloud APIs for Computer Vision: Up and Running in 15 Minutes ](https://learning.oreilly.com/library/view/practical-deep-learning/9781492034858/ch08.html).\n",
    "\n",
    "In this file we will compile the intermediate files that we need for the benchmarking.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Please download:\n",
    "\n",
    "- Gensim, which we will be using for comparing word similarity between ground truth with predicted class. Unzip and place the `GoogleNews-vectors-negative300.bin` within `data_path`. Download at: https://github.com/mmihaltz/word2vec-GoogleNews-vectors\n",
    "- The validation 2017 split from the MSCOCO website: http://cocodataset.org/#download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  tmp.zip\n",
      "mkdir: cannot create directory ‘data-may-2020’: File exists\n",
      "mv: cannot move 'annotations' to 'data-may-2020/annotations': Directory not empty\n"
     ]
    }
   ],
   "source": [
    "!wget -nc -q -O tmp.zip http://images.cocodataset.org/annotations/annotations_trainval2017.zip && unzip -n tmp.zip && rm tmp.zip\n",
    "!mkdir data-may-2020\n",
    "!mv annotations data-may-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directory structure should look as follows: \n",
    "\n",
    "```\n",
    "1-setup.ipynb\n",
    "2-compile-ground-truth-tags.ipynb\n",
    "3-upload-validation-images-to-cloud-providers.ipynb\n",
    "4-compile-results-tags.ipynb\n",
    "data-may-2020/\n",
    "|___________ GoogleNews-vectors-negative300.bin\n",
    "|___________ annotations/\n",
    "|___________ val2017/\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = <PATH_TO_IMAGES>\n",
    "annotation_filename = data_path + '/annotations/instances_val2017.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "with open(annotation_filename) as data_file:\n",
    "    annotations = json.load(data_file)\n",
    "\n",
    "# dictionary mapping from category to name\n",
    "class_data = annotations[\"categories\"]\n",
    "dict_class_to_name = dict(\n",
    "    [(class_data[i][\"id\"], class_data[i][\"name\"]) for i in range(len(class_data))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'person',\n",
      " 2: 'bicycle',\n",
      " 3: 'car',\n",
      " 4: 'motorcycle',\n",
      " 5: 'airplane',\n",
      " 6: 'bus',\n",
      " 7: 'train',\n",
      " 8: 'truck',\n",
      " 9: 'boat',\n",
      " 10: 'traffic light',\n",
      " 11: 'fire hydrant',\n",
      " 13: 'stop sign',\n",
      " 14: 'parking meter',\n",
      " 15: 'bench',\n",
      " 16: 'bird',\n",
      " 17: 'cat',\n",
      " 18: 'dog',\n",
      " 19: 'horse',\n",
      " 20: 'sheep',\n",
      " 21: 'cow',\n",
      " 22: 'elephant',\n",
      " 23: 'bear',\n",
      " 24: 'zebra',\n",
      " 25: 'giraffe',\n",
      " 27: 'backpack',\n",
      " 28: 'umbrella',\n",
      " 31: 'handbag',\n",
      " 32: 'tie',\n",
      " 33: 'suitcase',\n",
      " 34: 'frisbee',\n",
      " 35: 'skis',\n",
      " 36: 'snowboard',\n",
      " 37: 'sports ball',\n",
      " 38: 'kite',\n",
      " 39: 'baseball bat',\n",
      " 40: 'baseball glove',\n",
      " 41: 'skateboard',\n",
      " 42: 'surfboard',\n",
      " 43: 'tennis racket',\n",
      " 44: 'bottle',\n",
      " 46: 'wine glass',\n",
      " 47: 'cup',\n",
      " 48: 'fork',\n",
      " 49: 'knife',\n",
      " 50: 'spoon',\n",
      " 51: 'bowl',\n",
      " 52: 'banana',\n",
      " 53: 'apple',\n",
      " 54: 'sandwich',\n",
      " 55: 'orange',\n",
      " 56: 'broccoli',\n",
      " 57: 'carrot',\n",
      " 58: 'hot dog',\n",
      " 59: 'pizza',\n",
      " 60: 'donut',\n",
      " 61: 'cake',\n",
      " 62: 'chair',\n",
      " 63: 'couch',\n",
      " 64: 'potted plant',\n",
      " 65: 'bed',\n",
      " 67: 'dining table',\n",
      " 70: 'toilet',\n",
      " 72: 'tv',\n",
      " 73: 'laptop',\n",
      " 74: 'mouse',\n",
      " 75: 'remote',\n",
      " 76: 'keyboard',\n",
      " 77: 'cell phone',\n",
      " 78: 'microwave',\n",
      " 79: 'oven',\n",
      " 80: 'toaster',\n",
      " 81: 'sink',\n",
      " 82: 'refrigerator',\n",
      " 84: 'book',\n",
      " 85: 'clock',\n",
      " 86: 'vase',\n",
      " 87: 'scissors',\n",
      " 88: 'teddy bear',\n",
      " 89: 'hair drier',\n",
      " 90: 'toothbrush'}\n"
     ]
    }
   ],
   "source": [
    "pprint(dict_class_to_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path + \"/class-id-to-name.json\", \"w\") as outfile:\n",
    "    json.dump(dict_class_to_name, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COCO Image ID to category ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dictionary mapping from category to name\n",
    "image_id_to_category_id = []\n",
    "for key in annotations[\"annotations\"]:\n",
    "    image_id_to_category_id.append([key[\"image_id\"], key[\"category_id\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36781\n"
     ]
    }
   ],
   "source": [
    "print(len(image_id_to_category_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "output_filename = data_path + \"/coco-image-id-to-category-id.csv\"\n",
    "\n",
    "with open(output_filename, \"w\", newline=\"\\n\") as f:\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerows(image_id_to_category_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
